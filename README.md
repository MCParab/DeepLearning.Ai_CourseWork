# Deeplearning.ai

Contains list of research papers on deep learning, cited in all deeplearning.ai courses.

### SEQUENCE MODELS 

* #### WEEK 1 : RECURRENT NEURAL NETWORKS 
     1. [The Unresonable Effectiveness of Recurrent Neural Networks ](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) -- Andrej Karpathy blogs 
     2. [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)  -- colah's blogs
* #### WEEK 2 : NATRUAL LANGUAGE PROCESSING AND WORD EMBEDDINGS
     1. [Linguistic regularities in continous space word representation](https://www.aclweb.org/anthology/N13-1090) -- Microsoft Research Redmond, WA 98052
     2. [Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/abs/1301.3781) -- Thomas Mikolov, Kai Chen, Greg Corrado, Jeffrey Dean 
     3. [GloVe: Global Vectors for Word Representation](https://www.aclweb.org/anthology/D14-1162) -- Jeffrey Pennington, Richard Socher, Christopher D. Manning
     4. [Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings](https://arxiv.org/pdf/1607.06520.pdf) -- Tolga Bolukbasi, Kai-Wei Chang, James Zou, Venkatesh Saligrama, Adam Kalai
* #### WEEK 3 : SEQUENCE MODELS AND ATTENTION MECHANISM
     1. [Neural Machine Translation by jointly learning to align and translate](https://arxiv.org/pdf/1409.0473.pdf) -- Dzmitry Bahdanau, KyungHyun Cho, Yoshua Bengio
     2. [Show, Attend and Tell : Neural Image Caption Generation With Visual Attention](https://arxiv.org/abs/1502.03044) -- Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville, Yoshua Benjio
     3. [Connectionist Temporal Classification : Labelling Unsegmented Sequence Data with Recurrent Neural Networks](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.75.6306&rep=rep1&type=pdf) -- Alex Graves, Santiago Fernandez, Faustino Gomez, Jurgen Schmidhuber
